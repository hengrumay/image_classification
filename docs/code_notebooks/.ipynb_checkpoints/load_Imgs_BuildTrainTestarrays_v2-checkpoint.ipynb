{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNBALANCED DATASET \n",
    "- https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set  \n",
    "- http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/  \n",
    "- https://github.com/scikit-learn-contrib/imbalanced-learn  \n",
    "- https://shiring.github.io/machine_learning/2017/04/02/unbalanced  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### TRY small equal subset of ALL DATA  \n",
    "N=2000 each : a bit above chance model v0/v1 (acc~55-61%) || Not great ...  ref -- model_v1#.h5  \n",
    "Ref: http://localhost:8888/notebooks/load_Imgs_runtestCNN_v0.ipynb\n",
    "\n",
    "\n",
    "#### > TRY ALL DATA  -- 1:10 ratio train-test   \n",
    "not great -- zero recall for images with buildings... ref -- model_v2#.h5   \n",
    "Ref: http://localhost:8888/notebooks/load_Imgs_runtestCNN_v1.ipynb\n",
    "\n",
    "\n",
    "#### >> TRY Upsampling Bclass and Downsampling NBclass\n",
    "N=6000 each : PROMISING with cnn_model v3 (train-test acc~97%) | transfer_VGG16_model v4 (train-test acc~93%)   \n",
    "Ref: http://localhost:8888/notebooks/load_Imgs_runtestCNN_v1.ipynb     ||  http://localhost:8888/notebooks/load_Imgs_runtestCNN_v2_tryVGG16Transfer.ipynb\n",
    "- train-test: N=6000 each --- b_2000 + 4000_randomSampling || nb_6000   \n",
    "- ** however val data also has mixture of oversampled data... so not ideal...\n",
    "\n",
    "\n",
    "#### >>> TRY Using same (1:10)% but add Image Augmented Bclass to create similar # of samples in both classes  \n",
    "http://localhost:8888/notebooks/Use_ImageDataGenerator_makeSynthetic_v2.ipynb  \n",
    "train-test: N=10000 each --- b_1000 + aug_b_9000  || nb_10000   \n",
    "holdout: b_400 || nb_4000   \n",
    "Ref: http://localhost:8888/notebooks/load_Imgs_runtestCNN_v1-AugmentedXY.ipynb   || http://localhost:8888/notebooks/load_Imgs_runtestCNN_v1-AugmentedXY_run2.ipynb\n",
    " \n",
    "\n",
    "##  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General REQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# path='/Users/#####'\n",
    "# path = '/home/ubuntu/pynb/#####'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get fullpaths to img files\n",
    "import glob, os, sys\n",
    "\n",
    "btmp = glob.glob(os.path.join(path+'/building_set/buildings/','*.tif')) #os.listdir( path+'/building_set/buildings/' )\n",
    "# buildingFileNames\n",
    "\n",
    "abtmp = glob.glob(os.path.join(path+'/building_set/augmented/','*.tif')) #os.listdir( path+'/building_set/buildings/' )\n",
    "# augbuildingFileNames\n",
    "\n",
    "nbtmp = glob.glob(os.path.join(path+'/building_set/no_buildings/','*.tif')) #os.listdir( path+'/building_set/no_buildings' )\n",
    "# nobuildingFileNames\n",
    "\n",
    "# buildingFileNames = btmp\n",
    "# nobuildingFileNames = nbtmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abtmp[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 19989, 20000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(btmp), len(abtmp) , len(nbtmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400.0, 1600.0, 19600.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .2*2000, 2000 -.2*2000, 20000 -.2*2000\n",
    "# (400.0, 1600.0, 19600.0)\n",
    "\n",
    "factor = 0.2\n",
    "factor*2000, 2000 -factor*2000, 20000 -factor*2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define holdout | traintest data IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainTestHoldOutSplitIDX(holdoutSize, classSZ):\n",
    "    \n",
    "    holdID = np.random.choice(classSZ,holdoutSize,replace=False).tolist()\n",
    "    testID = list(set.difference(set(list(range(0,classSZ))),set(holdID)))\n",
    "        \n",
    "    return holdID, testID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bHoldID: 400   | bTrainTestID: 1600\n",
      "nbHoldID: 4000 | nbTrainTestID: 16000\n",
      "\n",
      "aBclassSZuse: 14400\n",
      "abTrainTestID: 14400\n",
      "\n",
      "bTrainTestID + abTrainTestID: 16000\n"
     ]
    }
   ],
   "source": [
    "BclassSZ = len(btmp)\n",
    "aBclassSZ = len(abtmp)\n",
    "NBclassSZ = len(nbtmp)\n",
    "\n",
    "bHoldID, bTrainTestID = getTrainTestHoldOutSplitIDX(int(0.2*BclassSZ), BclassSZ)\n",
    "nbHoldID, nbTrainTestID = getTrainTestHoldOutSplitIDX(int(0.2*NBclassSZ), NBclassSZ)\n",
    "\n",
    "print('bHoldID: {0}   | bTrainTestID: {1}'.format(len(bHoldID), len(bTrainTestID)) )\n",
    "print('nbHoldID: {0} | nbTrainTestID: {1}'.format(len(nbHoldID), len(nbTrainTestID)))\n",
    "print()\n",
    "\n",
    "aBclassSZuse = len(nbTrainTestID) - len(bTrainTestID)\n",
    "print('aBclassSZuse: {0}'.format(aBclassSZuse))\n",
    "\n",
    "abTrainTestID = np.random.choice(aBclassSZ,aBclassSZuse,replace=True).tolist()\n",
    "print('abTrainTestID: {0}'.format(len(abTrainTestID)))\n",
    "print()\n",
    "print('bTrainTestID + abTrainTestID: {0}'.format(len(abTrainTestID) + len(bTrainTestID)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Holdout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bHoldF0 = [btmp[i] for i in bHoldID]\n",
    "nbHoldF0 = [nbtmp[i] for i in nbHoldID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bHoldDF = pd.DataFrame(bHoldF0, columns=['filename'])\n",
    "bHoldDF['Blabel'] = 1\n",
    "bHoldDF['augment'] = 0\n",
    "\n",
    "nbHoldDF = pd.DataFrame(nbHoldF0, columns=['filename'])\n",
    "nbHoldDF['Blabel'] = 0\n",
    "nbHoldDF['augment'] = 0\n",
    "\n",
    "holdFileIdx_all = pd.concat([bHoldDF,nbHoldDF]).reset_index()\n",
    "holdFileIdx_all.rename(columns={'index':'Oidx'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4400, 4)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdFileIdx_all.shape #(4400, 3) || index reset (4400, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# holdFileIdx_all.to_csv(path+'/building_set/XY_holdout_all.csv')\n",
    "# FileImgPaths.to_csv(path+'/building_set/XY_holdout_all.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get filepaths of keras ImageDataGenerator randomly-augmented files that DO NOT correspond to holdOUT building image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(1600,)\n",
      "15993\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# hold = pd.read_csv('./building_set/XY_holdout_all.csv',index_col=0)\n",
    "hold =holdFileIdx_all\n",
    "\n",
    "# [i.split('/')[-1][:-4] for i in hold.filename]\n",
    "hold['fileNo']=hold.filename.apply(lambda x: x.split('/')[-1][:-4])\n",
    "\n",
    "bFno = hold[hold.Blabel==1].fileNo\n",
    "print(bFno.shape)\n",
    "\n",
    "# abtmp[100].split('/')[-1].split('__')\n",
    "# ['b_585046', '0_8370.tif']\n",
    "# abtmp[100].split('/')[-1].split('__')[0][2:]\n",
    "\n",
    "getFilePrefixes = [ab.split('/')[-1].split('__')[0][2:] for ab in abtmp]\n",
    "\n",
    "nonHold_getFileNo = [f for f in getFilePrefixes if int(f) not in list(bFno.astype(int))]\n",
    "\n",
    "print(np.unique(nonHold_getFileNo).shape)\n",
    "\n",
    "nonHold_Filepath = [ab for ab in abtmp  \n",
    "                    if int(ab.split('/')[-1].split('__')[0][2:]) in list(pd.Series(nonHold_getFileNo, dtype='int'))]\n",
    "\n",
    "print(len(nonHold_Filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonHold_Filepath[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Derive filelists for traintest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IF using ALL remaining files... NOT USING wrt MEMORY overload....\n",
    "\n",
    "bTrainTestF0 = [btmp[i] for i in bTrainTestID]\n",
    "abTrainTestF0 = [abtmp[i] for i in abTrainTestID]\n",
    "nbTrainTestF0 = [nbtmp[i] for i in nbTrainTestID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOT using all remaining files -- memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nimg = 10000\n",
    "\n",
    "btmp1 = [btmp[i] for i in np.random.choice(len(btmp),int(0.1*Nimg),replace=False).tolist()]\n",
    "\n",
    "abtmp1 = [nonHold_Filepath[i] for i in np.random.choice(len(nonHold_Filepath),\n",
    "                                                        #Nimg-len(bTrainTestF0)-len(bHoldID),replace=True).tolist()]\n",
    "                                                        Nimg-int(0.1*Nimg),replace=False).tolist()]\n",
    "\n",
    "nbtmp1 = [nbtmp[i] for i in np.random.choice(len(nbtmp),Nimg,replace=False).tolist()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9000, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(btmp1), len(abtmp1), len(nbtmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### rename... traintest tmp filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bTrainTestF1 = btmp1\n",
    "abTrainTestF1 = abtmp1\n",
    "nbTrainTestF1 = nbtmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TMP = bTrainTestF0[:]\n",
    "# len(TMP) #1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TMP.extend(abTrainTestID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(TMP),len(abTrainTestID)\n",
    "# # (16000, 14400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat traintest filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IF Using ALL remaining files\n",
    "# bTrainTestDF = pd.DataFrame(bTrainTestF0, columns=['filename'])\n",
    "# bTrainTestDF['Blabel'] = 1\n",
    "# bTrainTestDF['augment'] = 0\n",
    "\n",
    "# abTrainTestDF = pd.DataFrame(abTrainTestF0, columns=['filename'])\n",
    "# abTrainTestDF['Blabel'] = 1\n",
    "# abTrainTestDF['augment'] = 1\n",
    "\n",
    "# nbTrainTestDF = pd.DataFrame(nbTrainTestF0, columns=['filename'])\n",
    "# nbTrainTestDF['Blabel'] = 0\n",
    "# nbTrainTestDF['augment'] = 0\n",
    "\n",
    "# traintestFileIdx_all = pd.concat([bTrainTestDF,abTrainTestDF,nbTrainTestDF])\n",
    "# traintestFileIdx_all = pd.concat([bTrainTestDF,abTrainTestDF,nbTrainTestDF]).reset_index()\n",
    "# traintestFileIdx_all.rename(columns={'index':'Oidx'}, inplace=True)\n",
    "\n",
    "#.shape #(32000, 3) --> TOO LARGE to hold in memory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## USING Nimg -------------------------------------------------------\n",
    "bTrainTestDF = pd.DataFrame(bTrainTestF1, columns=['filename'])\n",
    "bTrainTestDF['Blabel'] = 1\n",
    "bTrainTestDF['augment'] = 0\n",
    "\n",
    "abTrainTestDF = pd.DataFrame(abTrainTestF1, columns=['filename'])\n",
    "abTrainTestDF['Blabel'] = 1\n",
    "abTrainTestDF['augment'] = 1\n",
    "\n",
    "nbTrainTestDF = pd.DataFrame(nbTrainTestF1, columns=['filename'])\n",
    "nbTrainTestDF['Blabel'] = 0\n",
    "nbTrainTestDF['augment'] = 0\n",
    "\n",
    "traintestFileIdx_all = pd.concat([bTrainTestDF,abTrainTestDF,nbTrainTestDF]).reset_index()\n",
    "traintestFileIdx_all.rename(columns={'index':'Oidx'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintestFileIdx_all.shape #.iloc[list(range(1601,1800))]#.shape #(32000, 3) --> TOO LARGE to hold in memory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintestFileIdx_all.Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4000\n",
       "1     400\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdFileIdx_all.Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define basic image preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import color, exposure, transform\n",
    "\n",
    "# NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img=np.array(img)\n",
    "    # Histogram normalization in v channel\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central square crop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE), mode='constant')\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    #img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define function to load & run image processing --> image np_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def get_Fileclass(img_path):\n",
    "    return str(img_path.split('/')[-2])\n",
    "\n",
    "def get_FileName(img_path):\n",
    "    return str(img_path.split('/')[-1])\n",
    "\n",
    "\n",
    "\n",
    "def makeImageXYvars(FileIdx_file):\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    cnt = 0\n",
    "    N = 0 \n",
    "    imgN = 500\n",
    "    \n",
    "    \n",
    "    FileImgPaths = FileIdx_file\n",
    "\n",
    "    # for img_path in TrainImgPaths.filename:\n",
    "    for img_path in FileImgPaths.filename:    \n",
    "\n",
    "        img = preprocess_img(io.imread(img_path))  ## add image more pre-processing later...\n",
    "\n",
    "        label = get_Fileclass(img_path)\n",
    "        #print('preprocessing image : '+ label + ' -- ' + get_FileName(img_path))\n",
    "\n",
    "        imgs.append(img)\n",
    "        #labels.append(label)\n",
    "\n",
    "        if cnt%imgN==0:\n",
    "            if N==0 & cnt==0:\n",
    "                print('start processing....')\n",
    "            else:\n",
    "                print('preprocessed {0} images ...'.format((N*imgN)))\n",
    "            N += 1\n",
    "        \n",
    "    cnt += 1\n",
    "        \n",
    "    if cnt>=len(FileIdx_file):\n",
    "        ## Done... print:            \n",
    "        print('preprocessed {0} images ...'.format(cnt))\n",
    "    \n",
    "    \n",
    "    X = np.array(imgs, dtype='float32')\n",
    "\n",
    "    # Make one hot targets\n",
    "    Y= FileImgPaths.Blabel.values \n",
    "\n",
    "    return X, Y, FileImgPaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run image processing --> np_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X,Y, FileImgPaths = makeImageXYvars(FileIdx_Train)\n",
    "# X,Y, FileImgPaths = makeImageXYvars(FileIdx_Test)\n",
    "\n",
    "\n",
    "# X,Y, FileImgPaths = makeImageXYvars(holdFileIdx_all)\n",
    "X,Y, FileImgPaths = makeImageXYvars(traintestFileIdx_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000,), array([1, 1, 1, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, Y\n",
    "#holdout ((4400,), array([1, 1, 1, ..., 0, 0, 0]))\n",
    "#testtrain ((20000,), array([1, 1, 1, ..., 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### RESHAPE Y --- maybe do this when running the convnet -- combine y+imagefilename so they correspond ???\n",
    "from keras.utils import np_utils\n",
    "Y=np_utils.to_categorical(Y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 256, 256, 3)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "#holdout (4400, 256, 256, 3)\n",
    "# testtrain (20000, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.backend.image_data_format()\n",
    "# 'channels_last'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SAVE FILES\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# np.save(path+'/building_set/TrainX_v0',X)\n",
    "# np.save(path+'/building_set/TrainY_v0',Y)\n",
    "\n",
    "\n",
    "# np.save(path+'/building_set/TestX_v0',X)\n",
    "# np.save(path+'/building_set/TestY_v0',Y)\n",
    "\n",
    "\n",
    "## LARGE files....\n",
    "# np.save(path+'/building_set/X_all',X)\n",
    "# np.save(path+'/building_set/Y_all',Y)\n",
    "\n",
    "# np.save(path+'/building_set/X_ubdnb6000_all',X)\n",
    "# np.save(path+'/building_set/Y_ubdnb6000_all',Y)\n",
    "# FileImgPaths.to_csv(path+'/building_set/XY_ubdnb6000_all.csv')\n",
    "\n",
    "\n",
    "\n",
    "np.save(path+'/building_set/X_holdout_all',X)\n",
    "np.save(path+'/building_set/Y_holdout_all',Y)\n",
    "# FileImgPaths.to_csv(path+'/building_set/XY_holdout_all.csv')\n",
    "holdFileIdx_all.to_csv(path+'/building_set/XY_holdout_all.csv')\n",
    "\n",
    "np.save(path+'/building_set/X_traintest_all',X)\n",
    "np.save(path+'/building_set/Y_traintest_all',Y)\n",
    "# FileImgPaths.to_csv(path+'/building_set/XY_traintest_all.csv')\n",
    "traintestFileIdx_all.to_csv(path+'/building_set/XY_traintest_all.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD saved vars\n",
    "\n",
    "\n",
    "# f = np.load('filepath.npy')\n",
    "# f.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tt =pd.read_csv(path+'/building_set/XY_holdout_all.csv', index_col=0)\n",
    "tt =pd.read_csv(path+'/building_set/XY_testtrain_all.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = holdFileIdx_all.reset_index()\n",
    "# t.rename(columns={'index':'Oidx'}, inplace=True)\n",
    "# t.index.duplicated().sum()\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK train-test-split | images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Include all images\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,test = train_test_split(holdFileIdx_all, test_size=0.2, stratify=holdFileIdx_all.Blabel)\n",
    "train1,test1 = train_test_split(traintestFileIdx_all, test_size=0.2, stratify=traintestFileIdx_all.Blabel)\n",
    "\n",
    "# Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, \n",
    "#                                                 test_size=0.2, random_state=4859, \n",
    "#                                                 stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3520, 880, 16000, 4000)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test) , len(train1), len(test1)\n",
    "#holdout (3520, 880)\n",
    "# testtrain (16000, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdFileIdx_all.index.duplicated().sum() , traintestFileIdx_all.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintestFileIdx_all.Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.index.duplicated().sum(), test1.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8000\n",
       "0    8000\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintestFileIdx_all.iloc[train1.index.tolist()].Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2000\n",
       "0    2000\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintestFileIdx_all.iloc[test1.index.tolist()].Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index.duplicated().sum(), test.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800\n",
       "1     80\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdFileIdx_all.iloc[test.index.tolist()].Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3200\n",
       "1     320\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdFileIdx_all.iloc[train.index.tolist()].Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traintestFileIdx_all.iloc[train1.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "holdFileIdx_all.iloc[train.index.tolist()]#Blabel.value_counts() #>>#reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img #, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TrainTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "img=load_img(traintestFileIdx_all.iloc[train1.index.tolist()[n]].filename)\n",
    "print(traintestFileIdx_all.iloc[train1.index.tolist()[n]].Blabel ,\n",
    "      ' || [nB : B] == {}'.format(Y[train1.index.tolist()[n]]) )\n",
    "plt.imshow(img)\n",
    "\n",
    "# 0  || [nB : B] == [ 1.  0.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[train1.index.tolist()[n],:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "img=load_img(traintestFileIdx_all.iloc[train1.index.tolist()[n]].filename)\n",
    "print(traintestFileIdx_all.iloc[train1.index.tolist()[n]].Blabel ,\n",
    "      ' || [nB : B] == {}'.format(Y[train1.index.tolist()[n]]) )\n",
    "plt.imshow(img)\n",
    "\n",
    "# 1  || [nB : B] == [ 0.  1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[train1.index.tolist()[n],:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "img=load_img(holdFileIdx_all.iloc[train.index.tolist()[n]].filename)\n",
    "print(holdFileIdx_all.iloc[train.index.tolist()[n]].Blabel , ' || [nB : B] == {}'.format(Y[train.index.tolist()[n]]) )\n",
    "plt.imshow(img)\n",
    "\n",
    "# 0  || [nB : B] == [ 1.  0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[train.index.tolist()[n],:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "img=load_img(holdFileIdx_all.iloc[train.index.tolist()[n]].filename)\n",
    "print(holdFileIdx_all.iloc[train.index.tolist()[n]].Blabel , ' || [nB : B] == {}'.format(Y[train.index.tolist()[n]]) )\n",
    "plt.imshow(img)\n",
    "\n",
    "# 1  || [nB : B] == [ 0.  1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[train.index.tolist()[n],:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "img=load_img(holdFileIdx_all.iloc[train.index.tolist()[n]].filename)\n",
    "print(holdFileIdx_all.iloc[train.index.tolist()[n]].Blabel , ' || [nB : B] == {}'.format(Y[train.index.tolist()[n]]) )\n",
    "plt.imshow(img)\n",
    "\n",
    "# 0  || [nB : B] == [ 1.  0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[train.index.tolist()[n],:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
