{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### UNBALANCED DATASET \n",
    "- https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set  \n",
    "- http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/  \n",
    "- https://github.com/scikit-learn-contrib/imbalanced-learn  \n",
    "- https://shiring.github.io/machine_learning/2017/04/02/unbalanced  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRY samesize DATA\n",
    "N=2000 each : a bit above chance model v0/v1 (acc~55-61%) || Not great ...  ref -- model_v1#.h5  \n",
    "Ref: http://localhost:8888/notebooks/load_Imgs_runtestCNN_v0.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General REQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# path='/Users/#####'\n",
    "# path = '/home/ubuntu/pynb/#####'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os, sys\n",
    "buildingFileNames = glob.glob(os.path.join(path+'/building_set/buildings/','*.tif')) #os.listdir( path+'/building_set/buildings/' )\n",
    "# buildingFileNames\n",
    "nobuildingFileNames = glob.glob(os.path.join(path+'/building_set/no_buildings/','*.tif')) #os.listdir( path+'/building_set/no_buildings' )\n",
    "# nobuildingFileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.choice(5, 3, replace=False)\n",
    "[buildingFileNames[i] for i in np.random.choice(len(buildingFileNames),4000,replace=True).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [nobuildingFileNames[i] for i in np.random.randint(0,len(nobuildingFileNames),2000).tolist()]\n",
    "[nobuildingFileNames[i] for i in np.random.choice(len(nobuildingFileNames),4000,replace=False).tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define traintest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "Train_Bfiles  = buildingFileNames[:1000]\n",
    "Test_Bfiles = buildingFileNames[1000:2000] #total files\n",
    "\n",
    "## No-Buildings --- there're actually 20,000 nb_cases!!! --> stratified/random sampling?\n",
    "Train_NBfiles  = nobuildingFileNames[:1000]\n",
    "Test_NBfiles = nobuildingFileNames[1000:2000]\n",
    "\n",
    "\n",
    "\n",
    "buildDF = pd.DataFrame(Train_Bfiles, columns=['filename'])\n",
    "buildDF['Blabel'] = 1\n",
    "nobuildDF = pd.DataFrame(Train_NBfiles, columns=['filename'])\n",
    "nobuildDF['Blabel'] = 0\n",
    "\n",
    "FileIdx_Train = pd.concat([buildDF,nobuildDF])\n",
    "\n",
    "\n",
    "\n",
    "buildDF = pd.DataFrame(Test_Bfiles, columns=['filename'])\n",
    "buildDF['Blabel'] = 1\n",
    "\n",
    "nobuildDF = pd.DataFrame(Test_NBfiles, columns=['filename'])\n",
    "nobuildDF['Blabel'] = 0\n",
    "\n",
    "FileIdx_Test = pd.concat([buildDF,nobuildDF])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SUBSEQUENTLY -- to try all images\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "#                                                     test_size=0.2, random_state=23, \n",
    "#                                                     stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FileIdx_Test==FileIdx_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "0    1000\n",
       "Name: Blabel, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FileIdx_Train.sample(2000).Blabel.value_counts()\n",
    "FileIdx_Test.sample(2000).Blabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define basic image preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import color, exposure, transform\n",
    "\n",
    "# NUM_CLASSES = 2\n",
    "IMG_SIZE = 256\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img=np.array(img)\n",
    "    # Histogram normalization in v channel\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central square crop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE), mode='constant')\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    #img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Define function to load & run image processing --> image np_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def get_Fileclass(img_path):\n",
    "    return str(img_path.split('/')[-2])\n",
    "\n",
    "def get_FileName(img_path):\n",
    "    return str(img_path.split('/')[-1])\n",
    "\n",
    "\n",
    "\n",
    "def makeImageXYvars(FileIdx_file):\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    cnt = 0\n",
    "    N = 0 \n",
    "    imgN = 500\n",
    "    \n",
    "\n",
    "    # TrainImgPaths = FileIdx_Train.ix[FileIdx_Train.sample(2000).Blabel.index.tolist()]\n",
    "    FileImgPaths = FileIdx_file.ix[FileIdx_file.sample(2000).Blabel.index.tolist()] #randomly samples each time...\n",
    "\n",
    "    # for img_path in TrainImgPaths.filename:\n",
    "    for img_path in FileImgPaths.filename:    \n",
    "\n",
    "        img = preprocess_img(io.imread(img_path))  ## add image more pre-processing later...\n",
    "\n",
    "        label = get_Fileclass(img_path)\n",
    "        #print('preprocessing image : '+ label + ' -- ' + get_FileName(img_path))\n",
    "\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if cnt%imgN==0:\n",
    "            N += 1\n",
    "            print('preprocessed {0} images ...'.format(N*imgN))\n",
    "        \n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "\n",
    "    # Make one hot targets\n",
    "    Y= FileImgPaths.Blabel.values \n",
    "\n",
    "    return X, Y, FileImgPaths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run image processing --> np_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X,Y, FileImgPaths = makeImageXYvars(FileIdx_Train)\n",
    "X,Y, FileImgPaths = makeImageXYvars(FileIdx_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y.shape, Y\n",
    "# ((4000,), array([1, 0, 1, ..., 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### RESHAPE Y\n",
    "from keras.utils import np_utils\n",
    "Y=np_utils.to_categorical(Y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SAVE FILES\n",
    "\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# np.save(path+'/building_set/TrainX_v0',X)\n",
    "# np.save(path+'/building_set/TrainY_v0',Y)\n",
    "\n",
    "\n",
    "# np.save(path+'/building_set/TestX_v0',X)\n",
    "# np.save(path+'/building_set/TestY_v0',Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 256, 256, 3) (4000, 2)\n",
      "(4000, 256, 256, 3) (4000, 2)\n"
     ]
    }
   ],
   "source": [
    "# LOAD saved vars\n",
    "\n",
    "\n",
    "Xtrain=np.load(path+'/building_set/TrainX_v0'+'.npy')\n",
    "Ytrain=np.load(path+'/building_set/TrainY_v0'+'.npy')\n",
    "print(Xtrain.shape, Ytrain.shape)\n",
    "\n",
    "\n",
    "Xtest=np.load(path+'/building_set/TestX_v0'+'.npy')\n",
    "Ytest=np.load(path+'/building_set/TestY_v0'+'.npy')\n",
    "print(Xtest.shape, Ytest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECK images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img #, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path+'/building_set/train/buildings/100208.tif')  # this is a PIL image of geotif file\n",
    "plt.imshow(img)\n",
    "np.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2 = preprocess_img(np.array(img)) #without rollaxis to see what img_preprocessing does...\n",
    "img2 = preprocess_img(img) \n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FileIdx_Test.values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FileIdx_Train.values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path+'/building_set/no_buildings/585824.tif')  # this is a PIL image of geotif file\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xtest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path+'/building_set/buildings/120509.tif')  # this is a PIL image of geotif file\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain.shape\n",
    "plt.imshow(Xtrain[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
